{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# --- COLAB TRAINER (MLP + MIXED REWARDS) ---\n",
        "!pip install -q python-chess\n",
        "import chess\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import time\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "x0pFY5uIvCez"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CONFIG ---\n",
        "MOUNT_PATH = '/content/drive'\n",
        "SAVE_DIR = '/content/drive/My Drive/ChessRL_Models'\n",
        "MODEL_NAME = 'chess_mlp_hybrid.pth'\n",
        "MODEL_PATH = os.path.join(SAVE_DIR, MODEL_NAME)\n",
        "\n",
        "TRAIN_BATCH_SIZE = 100  # Huge batch for GPU speed\n",
        "MAX_MOVES = 100         # Short games to learn openings/middlegames fast\n",
        "EPSILON_START = 0.9\n",
        "EPSILON_DECAY = 0.97    # Fast decay: Drops to smart play in ~40 batches\n",
        "MIN_EPSILON = 0.05\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# Setup Device\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Training on: {DEVICE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "netug0CbvFIT",
        "outputId": "9498f08b-c14c-4036-9c75-bd4aabf70a09"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Drive\n",
        "drive.mount(MOUNT_PATH)\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOLNo6u5vLvf",
        "outputId": "6b7d7aa0-fce7-49a4-8782-6644c0723f9e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. THE EYES (FLAT 768 INPUTS) ---\n",
        "def board_to_tensor(board):\n",
        "    piece_map = {\n",
        "        chess.PAWN: 0, chess.KNIGHT: 1, chess.BISHOP: 2,\n",
        "        chess.ROOK: 3, chess.QUEEN: 4, chess.KING: 5\n",
        "    }\n",
        "    # 768 inputs = 64 squares * 12 piece types\n",
        "    tensor = torch.zeros(768, dtype=torch.float32, device=DEVICE)\n",
        "\n",
        "    for i in range(64):\n",
        "        piece = board.piece_at(i)\n",
        "        if piece:\n",
        "            offset = piece_map[piece.piece_type]\n",
        "            color = 0 if piece.color == chess.WHITE else 6\n",
        "            idx = (offset + color) * 64 + i\n",
        "            tensor[idx] = 1.0\n",
        "    return tensor\n",
        "\n",
        "# --- 2. THE BRAIN (3-LAYER MLP) ---\n",
        "class ChessNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ChessNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(768, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 1) # Output: Board Value\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        return torch.tanh(self.fc4(x))\n",
        "\n",
        "# --- HELPER: MATERIAL SCORE ---\n",
        "def get_material_score(board):\n",
        "    values = {chess.PAWN: 1, chess.KNIGHT: 3, chess.BISHOP: 3, chess.ROOK: 5, chess.QUEEN: 9}\n",
        "    white = sum(values.get(p.piece_type, 0) for p in board.piece_map().values() if p.color == chess.WHITE)\n",
        "    black = sum(values.get(p.piece_type, 0) for p in board.piece_map().values() if p.color == chess.BLACK)\n",
        "    return white - black\n",
        "\n",
        "# --- HELPER: CHOOSE MOVE (EPSILON GREEDY) ---\n",
        "def choose_move(board, model, epsilon):\n",
        "    legal_moves = list(board.legal_moves)\n",
        "    if not legal_moves: return None\n",
        "\n",
        "    # Exploration\n",
        "    if random.random() < epsilon:\n",
        "        return random.choice(legal_moves)\n",
        "\n",
        "    # Exploitation (Pick best material move)\n",
        "    best_move = None\n",
        "    best_score = -float('inf')\n",
        "    turn_mult = 1 if board.turn == chess.WHITE else -1\n",
        "\n",
        "    for move in legal_moves:\n",
        "        board.push(move)\n",
        "        tensor = board_to_tensor(board)\n",
        "        with torch.no_grad():\n",
        "            score = model(tensor).item()\n",
        "        board.pop()\n",
        "\n",
        "        score *= turn_mult\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_move = move\n",
        "    return best_move"
      ],
      "metadata": {
        "id": "Y27jy0QNvucM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- SAVE CHECKPOINT ---\n",
        "def save_checkpoint(model, optimizer, epsilon, games):\n",
        "    state = {\n",
        "        'state_dict': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'epsilon': epsilon,\n",
        "        'games': games\n",
        "    }\n",
        "    torch.save(state, MODEL_PATH)\n",
        "    print(f\"Saved Checkpoint: {MODEL_PATH}\")\n",
        "\n",
        "def load_checkpoint(model, optimizer):\n",
        "    if os.path.exists(MODEL_PATH):\n",
        "        print(\"Found checkpoint! Loading...\")\n",
        "        checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)\n",
        "        print(checkpoint['epsilon'] , ' epsilon, games = ', checkpoint['games'])\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        return checkpoint['epsilon'], checkpoint['games']\n",
        "    return EPSILON_START, 0"
      ],
      "metadata": {
        "id": "jYuH1lmUvv9B"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- MAIN TRAINING LOOP ---\n",
        "brain = ChessNet().to(DEVICE)\n",
        "optimizer = optim.Adam(brain.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "epsilon, total_games = load_checkpoint(brain, optimizer)\n",
        "\n",
        "print(\"Starting Training...\")\n",
        "start_time = time.time()\n",
        "\n",
        "while True:\n",
        "    optimizer.zero_grad()\n",
        "    batch_loss = 0\n",
        "\n",
        "    # Play a batch of games\n",
        "    for _ in range(TRAIN_BATCH_SIZE):\n",
        "        board = chess.Board()\n",
        "        game_states = []\n",
        "        target_scores = []\n",
        "        moves = 0\n",
        "\n",
        "        curr_mat = get_material_score(board)\n",
        "\n",
        "        while not board.is_game_over() and moves < MAX_MOVES:\n",
        "            game_states.append(board_to_tensor(board))\n",
        "            prev_mat = curr_mat\n",
        "\n",
        "            move = choose_move(board, brain, epsilon)\n",
        "            board.push(move)\n",
        "            moves += 1\n",
        "\n",
        "            curr_mat = get_material_score(board)\n",
        "\n",
        "            # --- REWARD SYSTEM ---\n",
        "            if board.is_checkmate():\n",
        "                # Massive reward for winning\n",
        "                if board.result() == \"1-0\": score = 2.5\n",
        "                else: score = -2.5\n",
        "            else:\n",
        "                # Standard Material Reward\n",
        "                score = curr_mat / 40.0\n",
        "                # Stalling Penalty (force action)\n",
        "                if curr_mat == prev_mat: score -= 0.002\n",
        "\n",
        "            target_scores.append(score)\n",
        "\n",
        "        # Stack data for learning\n",
        "        t_states = torch.stack(game_states)\n",
        "        t_targets = torch.tensor(target_scores, dtype=torch.float32, device=DEVICE).view(-1, 1)\n",
        "\n",
        "        # Calculate Error\n",
        "        pred = brain(t_states)\n",
        "        loss = criterion(pred, t_targets)\n",
        "        loss = loss / TRAIN_BATCH_SIZE # Normalize\n",
        "        loss.backward()\n",
        "        batch_loss += loss.item()\n",
        "\n",
        "        total_games += 1\n",
        "\n",
        "    # Update Brain\n",
        "    optimizer.step()\n",
        "\n",
        "    # Decay Randomness\n",
        "    epsilon = max(MIN_EPSILON, epsilon * EPSILON_DECAY)\n",
        "\n",
        "    duration = time.time() - start_time\n",
        "    print(f\"Games: {total_games} | Eps: {epsilon:.4f} | Loss: {batch_loss:.5f} | Time: {duration:.1f}s\")\n",
        "\n",
        "    save_checkpoint(brain, optimizer, epsilon, total_games)\n",
        "    start_time = time.time() # Reset Timer"
      ],
      "metadata": {
        "id": "d32PmCp0AWWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jFZTN4qNwLOe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}